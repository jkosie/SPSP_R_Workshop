---
title: "SPSP R Workshop"
author: "Jessica E. Kosie"
date: "2/4/2019"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---
# Acknowledgements

+ Adapted from: [ICIS 2018: Open Science Tutorial](https://github.com/jkosie/openscience_tutorial)

+ Original content created by Jessica E. Kosie and [Michael C. Frank](https://web.stanford.edu/~mcfrank/)

+ Some additional content adapted from [R for Data Science](https://r4ds.had.co.nz/)

# Goals 

By the end of this tutorial, you will know:

+ Basic `R` usage (using `R` as a calculator, creating variables, indexing vectors)
+ How to read in and examine data
+ How to get values out of the rows and columns in your data
+ What a pipe is and how to use pipes to chain together `tidyverse` verbs
+ How to create useful summaries of your data using tidyverse
+ Basic understanding of how to create plots in `ggplot2`

The best way to do this tutorial is to walk through it slowly, executing each line and trying to understand what it does. You can execute a whole chunk at a time by hitting CMD+option+C (on a mac), and execute a single line by hitting CMD+enter (again on a mac). 

# Basic R Use

R can simply be used as a calculator.

```{r}
# Basic arithmetic
2+3
2*3
10/2
4^2

# Follows order of operations (PEMDAS)
(2^3)+4*(5/3)
```

These values aren't stored anywhere though. 

To keep them in memory, we need to assign them to a variable. 

```{r}
# Create a variable called x, that is assigned the number 8. 
x <- 8 
x = 8

# What value did I assign to x?
x

# What about y?
y

# Need to assign something to y!
y <- 2

y

# And we can do things with these variables:
x + y
x * y

z <- x * y

# Can also assign a range of values
x <- 1:5 #x is now a vector of 1, 2, 3, 4, 5

# Note that x is no longer 8, it take on whatever the most recent assignment was

# We can also assign a vector of values this way
x <- c(2, 8, 1, 9)
```

Vectors are just 1-dimensional lists of numbers.

```{r}
#let's get the numbers 1 thru 10 by ones 
1:10

#sequence of numbers, 1 thru 10, by 2
seq(from = 1, to = 10, by = 2) #can say "from", "to", and "by=", but they're not necessary

#sequence of 11 equally spaced numbers between 0 and 1
seq(from = 0, to = 1, length.out=11) 
```

> **Exercise 1.** Create a variable called x that is assigned the number 5. Create a variable called y that is a sequence of numbers from 5 to 25, by 5. Multiply x and y. What happens? 

```{r}




```

## Functions

`seq` that we used above is a **function**. Everything you typically want to do in statistical programming uses functions. `mean` is another good example. `mean` takes one **argument**, a numeric vector. We are going to **apply** this function to a new vector.

```{r}
z <- 0:20
mean(z)

# now, let's get the mean of this vector:
q <- c(2, 8, 6, NA, 4, 8)

mean(q)

# is that the answer you'd expect? let's get some information about the function `mean`
?mean

# we need to add an additional argument to tell the function that we want to ignore NAs (the default for this argument is FALSE, that's why NAs weren't ignored above)
mean(q, na.rm = TRUE)
```

> **Exercise 2.** R has a function called `rnorm` that will allow you to get a random sample of numbers drawn from a normal distribtuion. Get a sample of 5 numbers with a mean of 0 and a standard deviation of 0.5. Assign this to a varible (call it whatever you'd like).

```{r}
# Hint:
?rnorm



```

Creating and indexing matrices.

```{r}
x <- matrix(c(11,12,13,21,22,23), byrow=TRUE,nrow=2) #put into a matrix by row
x1 <- matrix(c(11,12,13,21,22,23), byrow=FALSE,nrow=2) #put into a matrix by column

#indexing matrices (getting the value that's in a particular row/column)

# x[r,c] would give you the element in row r, column c of the matrix

x[2,3] #gives you the element in row 2 column 3 of matrix x (defined above)
x[] #all rows, all columns - could have just typed x
x[1, ] #first row, all columns
x[ ,3] #all rows, third column
x[1,3] #first row, third column

y <- x[1,2] #assign the value in the 1st row 2nd column to a new variable

#what if I don't want these values in my environment any more?
rm(x)
rm(y)
rm(list = ls())

```
## Reading data into R

First, you'll need to tell R where to look for the data. To do this, you will set your working directory. (note that there are cases in which you won't have to set a working directory - using projects, for example - but I think it's an important R skill to know)

For this tutorial, your working directory should be wherever you downloaded the materials. 

Sometimes I like to do this using RStudio, via the graphical interface on the top:

Session > Set Working Directory > Set Working Directory to Source File Location

That will put you in the right location. 

```{r}
# what is my current working directory?
getwd()

setwd("~/Documents/School/Conferences/SPSP_2019/SPSP_R_Workshop")

# take a look at what's in your directory
# can also use the Files pane 
dir()

# Now, let's read in the mental_abacus_data CSV file and save it as an object called ma_data
ma_data <- read.csv("mental_abacus_data.csv", header = TRUE)
```

## Examining the data file

This dataset (described [here](https://github.com/mcfrank/openscience_tutorial/tree/master/datasets) come from [Barner et al. (2017), JNC](https://jnc.psychopen.eu/article/view/106), a classroom-randomized controlled trial of an elementary math intervention. The design was a simple pre-post assessment at the beginning and end of the school year. The primary question was whether assignment to group (control vs. mental abacus) produced differences in any of the outcomes (ravens:woodcockTotal). A secondary question was about the role of grade level and baseline math knowledge in the success of the intervention.

First, let's take a look at the data we'll be using:

We can simply look at the data frame. We can also get a summary of the data. (these are all **functions** too!)

```{r}
# Look at the first few rows of the data
head(ma_data)

# Look at the final few rows of the data
tail(ma_data)

# Get a summary of the data (spoiler alert: there are better ways to get summaries!)
summary(ma_data)

# Get an interactive spreadsheet view
View(ma_data)

```
## Indexing a data frame.

Just like we did before, you can select entries in the data frame like indexing a vector. [row, column]

```{r}
# Get the entry in row 4, column 3.
ma_data[4, 3]

# Get the entry in row 2 of the gonogo column
ma_data[2, "gonogo"] 

```

> ProTip: Many people use this kind of selection to modify individual entries, like if you just want to correct a single mistake at a paticular point in the data frame. Be careful if you do this, as there will be nothing in the code that tells you that `4` (for example) is the *right* element to fix, you'll just have to trust that you got that number right. 

```{r}
# for example:
ma_data[2, 1] <- NA

# now that entry is an NA
ma_data[2, 1]

# let's change it back
ma_data[2, 1] <- "S1-02-03"

```
...or select an entire column using the $ operation.

```{r}
ma_data$ravens
```

Create a new column from a current column(s).
```{r}
ma_data$ef <- ma_data$gonogo + ma_data$swm
```

We can apply functions to an entire column. For example, I can get the mean ravens score for my entire sample.

Note that I have to include the data file in this argument, if I just say mean(ravens) I'll get an error.

```{r}
mean(ma_data$ravens)
```

> **Exercise 3.** Let's center the ravens score. Create a new column called ravens_centered in which you center ravens by subtracting the mean of the ravens column from each entry in the ravens column. (Yes, there is a function for centering, but let's do it the long way for now!)

```{r}


```

# Using the `tidyverse`

  > tidyverse is a package that has to be installed and loaded before you can use any of its functions.
  
The functions we've been using so far have been in **base R** and don't require additional packages. To use the functions in the tidyverse packages the `tidyverse` package must first be installed and loaded. Tidyverse packages include tidyr, dplyr, ggplot2, and more - see here for more info: www.tidyverse.org.
  
If you haven't installed the package, you'll need to run this command once:

`install.packages("tidyverse")`

```{r}
# Load the package (tell R that you want to use its functions)
library("tidyverse")
```

We're going to reread the data now, using `read_csv`, which is the `tidyverse` version and works faster and better in a number of ways!

```{r}
ma_data <- read_csv("mental_abacus_data.csv")
```

## Pipes

Pipes are a way to write strings of functions more easily. They bring the first argument of the function (usually the data) to the beginning. So you can write:

```{r}
ma_data$ravens %>% mean()
```

That's not very useful yet, but when you start **nesting** functions, it gets better. 

```{r}
round(mean(ma_data$ravens), 
      digits = 2)

ma_data$ravens %>% mean %>% round(digits = 2)

# indenting makes things even easier to read
ma_data$ravens %>%
  mean %>% 
  round(digits = 2)
```

This can be super helpful for writing strings of functions so that they are readable and distinct. 

> **Exercise 4.** Rewrite these commands using pipes and check that they do the same thing! (Or at least produce the same output). Unpiped version:

```{r}
# number of unique values in the class_num column
length(unique(ma_data$class_num)) 
```

Piped version:

```{r}



```

## Using `tidyverse` to explore and characterize the dataset

We are going to manipulate these data using "verbs" from `dplyr`. I'll only teach four verbs, the most common in my workflow (but there are many other useful ones):

+ `filter` - remove rows by some logical condition
+ `mutate` - create new columns 
+ `group_by` - group the data into subsets by some column
+ `summarize` - apply some function over columns in each group  

Inspect the various variables before you start any analysis. Earlier we used `summary` but TBH I don't find it useful. 

```{r}
summary(ma_data)
```

This output just feels overwhelming and uninformative. 

You can look at each variable by itself:

```{r}
unique(ma_data$ravens)

ma_data$ravens %>%
 unique 
```

Or use interactive tools like `View` or `DT::datatable` (which I really like).

```{r}
View(ma_data)

# this won't work unless you first do
# install.packages("DT") 
DT::datatable(ma_data) 
```

## Filtering & Mutating

There are lots of reasons you might want to remove *rows* from your dataset, including getting rid of outliers, selecting subpopulations, etc. `filter` is a verb (function) that takes a data frame as its first argument, and then as its second takes the **condition** you want to filter on. 

So if you wanted to look only at instances where individuals scored higher than 16 on `ravens`.

```{r}
ma_data %>%
  filter(ravens > 16)

# filter(ma_data, ravens > 16)

```

Note that we're going to be using pipes with functions over data frames here. The way this works is that:

+ `dplyr` verbs always take the data frame as their first argument, and
+ because pipes pull out the first argument, the data frame just gets passed through successive operations
+ so you can read a pipe chain as "take this data frame and first do this, then do this, then do that."

This is essentially the huge insight of `dplyr`: you can chain verbs into readable and efficient sequences of operations over dataframes, provided 1) the verbs all have the same syntax (which they do) and 2) the data all have the same structure (which they do if they are tidy). 

OK, so filtering:

We could also look at only cases in which individuals scored greater than 16 on `ravens` but less than 20.
```{r}
ma_data %>%
  filter(ravens > 16, 
         ravens < 20)
```

> ProTip: You can think about `filter`ing as similar to "logical indexing", where you use a vector of `TRUE` and `FALSE`s to get a part of a dataset, for example, `ma_data[ma_data$group == "MA",]`. This command creates a logical vector `ma_data$group == "MA"` and uses it as a condition for filtering.

A quick aside about logical operators:
```{r}

# == operator tests for equality

a = 3 #assigning a value of 3 to a (same as a <- 3)
a == 3 #does a equal 3? YES
a == 4 #does a equal 4? NO

a = 4 #if I do this
a == 4 #now a is equal to 4? YES
a == 3 #is a equal to 3? NO (because we changed the value we assigned to a)

a != 4 #is a NOT equal to 4? NO
a != 3 #is a NOT equal to 3? YES

# < and > (tip - the PacMan wants to eat whatever is bigger, e.g. 4>3 or 5<10)
# <= >= less than or equal to and greater than or equal to

a > 3 #yes, a = 4, which is greater than 3
a < 3 #no, 4 is not less than 3
a > 4 #no, 4 is not greater than 4
a >= 4 #but it is greater than or equal to 4! (because a = 4)
a <= 4 #...and it's less than or equal to 4! (because a = 4)
```

> **Exercise 5.** Create a smaller datast with **only** individuals in first grade in the control (CNTL) group. 

```{r}



```
There are also times when you want to add or remove *columns*. You might want to remove columns to simplify the dataset. If you wanted to do that, the verb is `select`. 

```{r}
ma_data %>%
  select(subid, class_num, ravens) 

ma_data %>%
  select(-year) 

ma_data %>%
  select(1) 

ma_data %>%
  select(starts_with("gr")) 

# learn about this with ?select
```
Perhaps more useful is *adding columns*. You might do this perhaps to compute some kind of derived variable. `mutate` is the verb for these situations - it allows you to add a column. 

For example, maybe we want a column that represents a composite of gonogo and swm (like we added using *base R* above). Let's also add a column in which we center `ravens` as we did earlier in *base R*. We can do these both at once!
```{r}
ma_data <- ma_data %>%
  mutate(ef = gonogo + swm, 
         ravens_centered = ravens - mean(ravens))
```

## Standard psychological descriptives

We typically describe datasets at the level of subjects, not trials. We need two verbs to get a summary at the level of subjects: `group_by` and `summarise` (kiwi spelling). Grouping alone doesn't do much.
```{r}
ma_data %>%
  group_by(subid) 
```

All it does is add a grouping marker. 

What `summarise` does is to *apply a function* to a part of the dataset to create a new summary dataset. For example, we can apply the function `mean` to the dataset and get the grand mean. 

```{r}
ma_data %>%
  summarise(avg_ravens = mean(ravens))
```

Note the syntax here: `summarise` takes multiple  `new_column_name = function_to_be_applied_to_data(data_column)` entries in a list (like we saw with `mutate` above). Using this syntax, we can create more elaborate summary datasets also:

```{r}
ma_data %>%
  summarise(ravens_mean = mean(ravens), 
            ravens_sd = sd(ravens))
```

Where these two verbs shine is in combination, though. Because `summarise` applies functions to columns in your *grouped data*, not just to the whole dataset!

So we can group by whichever variable want and then carry out the same procedure, and all of a sudden we are doing something extremely useful!

Let's ignore pre and post test and just get the mean `ravens` for each subject.

```{r}
ravens_means <- ma_data %>%
  group_by(subid) %>%
  summarise(means = mean(ravens))

ravens_means
```

> **Exercise 6.** Let's compare whether the difference in pre- and post-intervention scores (i.e., `year`) on `ravens` differs for children in the control (`CNTL`) versus experimental (`MA`) groups. Use the functions `group` and `summarise` to produce a table of means and standard deviations across each of these four groups (1. CNTL pre-test; 2. CNTL post-test; 3. MA pre-test; MA post-test)

Hint: it is possible to group by two (or more) variables.

```{r}




```
## Graphing in ggplot2

Note: this is just the beginning! There are entire books on graphing in ggplot2! https://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/331924275X/ref=as_li_ss_tl?ie=UTF8&linkCode=sl1&tag=ggplot2-20&linkId=4b4de5146fdafd09b8035e8aa656f300

```{r}
ggplot(data = ma_data) +
  geom_point(mapping = aes(x = ravens, y = woodcockTotal))

#this is the ggplot version of:
plot(ma_data$ravens, ma_data$woodcockTotal)
```
Creation of a plot in ggplot2 begins with the function ggplot() which creates a coordinate system you can add data to. For example:
```{r}
ggplot(data = ma_data)
```
You then can add one or more layers to ggplot() to complete your graph. As above, we'll add a layer of points to our plot (creating a scatterplot). geom_point() is a *geom function*, each of which adds a different type of layer to a plot. Each *geom function* take a *mapping* argument that defines visual properties of the graph. 

Template for graphing in ggplot2:

ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))
  
```{r}
ggplot(data = ma_data) +
  geom_point(mapping = aes(x = ravens, y = woodcockTotal))
```
Let's say we want to visualize the relationship between `ravens` & `woodcockTotal` pre and post intervention (`year`). To visualize this, we are going to map `year` to an *aesthetic* (or a visual property of one of the objects in our plot). Aesthetics include things like size, shape, or color of our points. Let's map the color of our points to the `group` variable.
```{r}
ggplot(data = ma_data) +
  geom_point(mapping = aes(x = ravens, y = woodcockTotal, color = year))

#ggplot assigned each level of *color* to each unique value of `year`. This is called *scaling*.

#but - if `year` is a binary variable (2015 or 2016), why does the legend display a scale?
str(ma_data)

#we need to tell ggplot that `year` is a factor 
ggplot(data = ma_data) +
  geom_point(mapping = aes(x = ravens, y = woodcockTotal, color = factor(year)))

```

> **Exercise 7.** Options for *aesthetics* include color, shape, size, and alpha. Create a scatter plot to visualize the relationship between `gonogo` and `swm`. Add an aesthetic to visualize the effect of `grade`. Choose any aesthetic you'd like or play around with a few. What do they do? How might you use more than one aesthetic?

Do we need to specify that `grade` is a factor?

```{r}



```

> ProTip: We could also make separate graphs for each level of `grade` using `facet_wrap` by passing a formula (data structure) to `facet_wrap`. I use this often!

Here's how:
```{r}
ggplot(data = ma_data) +
  geom_point(mapping = aes(x = gonogo, y = swm, color = grade)) +
  facet_wrap(~ grade)
```
Maybe we'd prefer a line graph instead of a scatterplot to describe the relationship between `ravens` and `woodcockTotal`. In this case, we'd use a different *geom* (e.g., point, line, smooth, boxplot, bar). 

Let's make the same plot, using the smooth *geom* which fits a smoothed line to the data.
```{r}
ggplot(data = ma_data) +
  geom_smooth(mapping = aes(x = ravens, y = woodcockTotal))

#loess is the default function for geom_smooth() 
# from http://www.statisticshowto.com/lowess-smoothing/: LOWESS (Locally Weighted Scatterplot Smoothing), sometimes called LOESS (locally weighted smoothing), is a popular tool used in regression analysis that creates a smooth line through a timeplot or scatter plot to help you to see relationship between variables and foresee trends.
```
We can add aesthetics to help visualize the data:
```{r}
ggplot(data = ma_data) +
  geom_smooth(mapping = aes(x = ravens, y = woodcockTotal, linetype = factor(year), color = factor(year)))

```
We can also layer multiple geoms in the same plot!
```{r}
ggplot(data = ma_data) +
  geom_point(mapping = aes(x = ravens, y = woodcockTotal)) +
  geom_smooth(mapping = aes(x = ravens, y = woodcockTotal)) 

#we could also have used global mappings
ggplot(data = ma_data, mapping = aes(x = ravens, y = woodcockTotal)) +
  geom_point() +
  geom_smooth()

#finally, we can add an *aesthetic* to only one part of the graph
ggplot(data = ma_data, mapping = aes(x = ravens, y = woodcockTotal)) +
  geom_point(mapping = aes(color = factor(year))) +
  geom_smooth()
```

> **Exercise 8.** Plot the relationship between `pvAvg` and `arithmeticTotal`. As above, create lines overlaid on a scatter plot. For the points, use different colors for each level of `group` (i.e., whether they were in the mental abacus versus control group). For the lines, use both different colors and line types for `pluribus`.

```{r}




```
Now let's try a bar plot. We can combine what we've done above with plotting in ggplot to examine the avearge `ravens` for each level of `group` (intervention vs. control).

First, we'll need to use the skills we've previously acquired to create a table of means that we'll then plot. We'll then use the argument stat = "identity" to map the mean value onto the y aesthetic.
```{r}
plot.data <- ma_data %>% 
  group_by(year) %>% 
  summarise(mean = mean(ravens))

ggplot(plot.data, aes(x=factor(year), y=mean)) +
  geom_bar(stat="identity")

#more options:
ggplot(plot.data, aes(x=factor(year), y=mean, color = factor(year))) +
  geom_bar(stat="identity")

ggplot(plot.data, aes(x=factor(year), y=mean, fill = factor(year))) +
  geom_bar(stat="identity")

```

> **Exercise 9.** Earlier we looked at whether the difference in pre- and post-intervention scores (i.e., `year`) on `ravens` differs for children in the control (`CNTL`) versus experimental (`MA`) groups. Let's plot these differences. Create one graph for the intervention group and another for the control group.

Hint: See `facet_wrap` above.

```{r}




```


